#!/usr/bin/env bash

# Sorry, everyone
if (( ${BASH_VERSION%%.*} < 4 )); then
  echo "This script requires Bash >= 4. On OSX, try: brew install bash"
  exit 1
fi

# Any error is fatal.
set -e
set -o pipefail
# set -x # uncomment for debugging.
# set -u

# Known URLs, directories and versions
OPAM_URL=https://github.com/fdopen/opam-repository-mingw/releases/download/0.0.0.2/opam64.tar.xz
MINIMAL_OCAML_VERSION=4.10.0
OPAM_VERSION=4.12.0+mingw64c

SED=$(which gsed >/dev/null 2>&1 && echo gsed || echo sed)
MAKE=$(which gmake >/dev/null 2>&1 && echo gmake || echo make)

# OPAM_AUTO_SETUP defines the opam command-line option to
# automatically setup environment variables into
# $EVEREST_ENV_DEST_FILE . By default, it is left empty, but it is set
# to --auto-setup if everest is run with --yes, i.e. in
# non-interactive mode
OPAM_AUTO_SETUP=

ADVANCE_YES=false

IS_ARCHIVE=false
VALE_ARCHIVE=true

# No-interaction when this script is used for CI purposes
INTERACTIVE=true
make_non_interactive () {
  INTERACTIVE=false
  export GIT_SSH_COMMAND="ssh -oBatchMode=yes"
  export GIT_TERMINAL_PROMPT=0
  export OPAMYES=1
  export NOSHORTLOG=1
  export ADVANCE_YES=true
  OPAM_AUTO_SETUP=--auto-setup
}

# The parallel option, either empty (by default), or -j n,
# as specified on the command line.
# WARNING: in the latter case, it MUST be interpreted as two words, so
# NEVER quote it as "$parallel_opt"
# Use $parallel_opt instead
unset parallel_opt

# The -k option (to instruct make to keep going upon a failure),
# disabled by default
unset keep_going_opt

# A string made of both options above, for convenience
unset make_opts

set_make_opts () {
  make_opts="$parallel_opt $keep_going_opt"
}

# The file where to store customized environment variables
if [[ $EVEREST_ENV_DEST_FILE == "" ]] ; then
  # For people who have installed and initialized opam prior to
  # running ./everest check, opam will modify .profile instead of
  # .bash_profile, if the latter does not exist. So we need to
  # account for that case.
  if [[ -f "$HOME/.bash_profile" ]] ; then
      EVEREST_ENV_DEST_FILE="$HOME/.bash_profile"
  else
      EVEREST_ENV_DEST_FILE="$HOME/.profile"
  fi
fi

# The whole script makes the assumption that we're in the everest directory;
# this is a conservative method that ensures we switch to this directory first
# thing. Basically, this supports:
# - calling "everest" (in the PATH)
# - calling "./everest" (same directory)
# - calling "/path/to/everest"
# - calling "../path/to/everest"
# This bails for corner cases, e.g. "source everest" or "wget http://.../everest | bash"
cd_to_everest () {
  echo -n "# Switching to the everest directory"
  if [[ ${0##*/} != "everest" ]]; then
    echo -e "\nThis script must be called via ./everest"
    exit 1
  fi
  if [[ $0 != ${0#*/} ]]; then
    # Relative or absolute path (contains /)
    cd $(dirname $0)
  else
    # Called via the path
    cd $(dirname $(which $0))
  fi
  echo " ... now in $(pwd)"
  echo
}
# Save the initial working directory, to switch to when $0 pull calls
# the new version of $0
initial_pwd="$(pwd)"
cd_to_everest

check_no_archive () {
  if $IS_ARCHIVE; then
    red "This is an archived Everest repo, and the command you attempted to run \
         is not supported."
    red "To proceed anyway *at your own risk*, set the IS_ARCHIVE variable to \
         false within this script and re-run."
    exit 1
  fi
}

# "Modularity": include other files (requires us to be in the right directory)
source lib.sh
source repositories.sh
source hashes.sh

GETOPT=getopt
if is_osx; then
  export PATH=$(brew --prefix gnu-getopt)/bin:$PATH
  echo $PATH
fi

# -allow a command to fail with !â€™s side effect on errexit
# -use return value from ${PIPESTATUS[0]}, because ! hosed $?
! $GETOPT --test > /dev/null
if [[ ${PIPESTATUS[0]} -ne 4 ]]; then
  echo "you have an antiquated getopt; on Mac OS X, run \"brew install gnu-getopt\" and make sure it comes first in the PATH"
  exit 1
fi

# May be overridden to include a single project
ALL_PROJECTS="${!repositories[@]}"
SELECTIVE=false
# ^ Whether we are only running over a subset of the projects

# ------------------------------------------------------------------------------
# A series of helpers
# ------------------------------------------------------------------------------

write_to_env_dest_file () {
  str="$1"
  # NOTE: "$str" contains line breaks, since it actually contains
  # several commands, with each command on its own line.
  # These line breaks must be preserved.
  eval "$str"
  echo "$str" >> "$EVEREST_ENV_DEST_FILE"
  magenta "Remember to run source \"$EVEREST_ENV_DEST_FILE\" in your terminal afterwards!"
}

# Append $1 to the (Cygwin) path
windows_append_path () {
  path=$(cygpath -m -d "$1")
  path=$(cygpath "$path")
  str="
    # This line automatically added by $0
    export PATH=\"$path\":\$PATH"
  write_to_env_dest_file "$str"
  export PATH="$path":"$PATH"
}

# Windows requires several tools that can be installed via Visual Studio, but
# these usually aren't in the PATH. Check in the usual locations, then offer to
# customize "$EVEREST_ENV_DEST_FILE"
#   $1: name of command to check for
#   $2: candidate directory where it may reside
windows_check_or_modify_env_dest_file () {
  if ! command -v $1 >/dev/null 2>&1; then
    red "ERROR: $1 not found in PATH"
    if [ -f "$2"/$1 ]; then
      magenta "$1 found in $2; add to PATH via $EVEREST_ENV_DEST_FILE ? [Yn]"
      if prompt_yes true false; then
        windows_append_path "$2"
      fi
    else
      red "$1 not found in $2, bailing"
      echo Hint: it looks like some VS2015 components are missing. We need \
        VS2015, including the C++ components. You can run the VS2015 installer \
        and choose a custom setup, to ensure you have both F# and the C++ \
        components. Download it from: \
        https://go.microsoft.com/fwlink/?LinkId=532606&clcid=0x409
      exit 1
    fi
  fi

  echo "... found $1"
}

write_z3_env_dest_file () {
  str="
    # This line automatically added by $0
    export PATH=$(pwd)/$1/bin:\$PATH"
  write_to_env_dest_file "$str"
}

write_cygwin_env_dest_file () {
  str="
    # These lines automatically added by $0
    export PATH=/usr/x86_64-w64-mingw32/sys-root/mingw/bin:\$PATH
    export CYGWIN='winsymlinks:native'"
  write_to_env_dest_file "$str"
}

write_cxx_env_dest_file () {
  str="
    # This line automatically added by $0
    export CXX=x86_64-w64-mingw32-g++.exe"
  write_to_env_dest_file "$str"
}

cygsetup="setup-x86_64.exe"
cygsetup_args="--no-desktop --no-shortcuts --no-startmenu --wait --quiet-mode"
# Find Cygwin's setup utility, or download it from the internet.
# Success: writes the path to Cygwin's setup in $cygsetup
# Failure: aborts.
find_cygsetup () {
  found=false
  for s in "$USERPROFILE/Desktop/setup-x86_64.exe" "$USERPROFILE/Downloads/setup-x86_64.exe" "./setup-x86_64.exe" "c:/cygwin64/setup-x86_64.exe"; do
    if [ -x "$s" ]; then
      echo "Found $cygsetup"
      found=true
      cygsetup="$s"
    fi
  done

  # Try to find chocolatey version
  if ! $found; then
    for s in "$USERPROFILE/Desktop/cygwinsetup.exe" "$USERPROFILE/Downloads/cygwinsetup.exe" "./cygwinsetup.exe" "c:/cygwin64/cygwinsetup.exe"; do
     if [ -x "$s" ]; then
       echo "Found $cygsetup"
       found=true
       cygsetup="$s"
      fi
    done
  fi

  if ! $found; then
    magenta "Cygwin setup not found, downloading it"
    if ! command -v wget >/dev/null 2>&1; then
      red "ERROR: please either place cygwin's setup-x86_64.exe in your Downloads or Desktop folder, or install wget via cygwin's setup"
    fi
    wget "https://cygwin.com/setup-x86_64.exe"
    chmod a+x setup-x86_64.exe
    cygsetup=./setup-x86_64.exe
  fi
}

install_all_opam_packages () {
  packages=$(cat opam-packages | cut -d ' ' -f 2 | tr '\n' ' ')
  opam update
  if is_windows; then
    opam install depext-cygwinports
  fi
  opam depext $packages
  opam install -j 4 $packages
}

try_git_clone () {
  if ! git clone --recursive $1 $3; then
    magenta "Proceed with https? [Yn]"
    prompt_yes true "exit 1"
    git clone --recursive $2 $3
  fi
}

parse_z3_version () {
  if ! which z3 >/dev/null 2>&1; then
    echo "no z3 in path!"
  else
    local z3_version=$(z3 --version)
    if echo $z3_version | grep hashcode >/dev/null 2>&1; then
      z3 --version | $SED 's/.*build hashcode \(.*\)/\1/' | tr -d '\r'
    else
      z3 --version | $SED 's/Z3 version \([0-9\.]\+\).*/\1/'
    fi
  fi
}

# ------------------------------------------------------------------------------
# The functions that implement the main actions
# ------------------------------------------------------------------------------

do_update_z3 () {
  # Update our clone of FStarLang/binaries and check that we have the blessed z3
  # version
  if ! [[ -d fstarlang_binaries ]]; then
    echo "... cloning FStarLang/binaries"
    try_git_clone "git@github.com:FStarLang/binaries.git" "https://github.com/FStarLang/binaries.git" fstarlang_binaries
  fi
  (cd fstarlang_binaries && git fetch && git checkout z3-4.8.5 && git reset --hard origin/z3-4.8.5)

  local current_z3=$(parse_z3_version)
  echo "... version of z3 found in PATH: $current_z3"

  if is_windows; then
    local new_z3_file=fstarlang_binaries/z3-tested/z3-4.8.5*-x64-win.zip
  elif is_osx; then
    local new_z3_file=fstarlang_binaries/z3-tested/z3-4.8.5*-x64-osx-*.zip
  elif [[ $(lsb_release -i | awk '{ print $3; }') == "Ubuntu" ]]; then
    local new_z3_file=fstarlang_binaries/z3-tested/z3-4.8.5*-x64-ubuntu-14.04.zip
  elif [[ $(lsb_release -i | awk '{ print $3; }') == "Debian" ]]; then
    local new_z3_file=fstarlang_binaries/z3-tested/z3-4.8.5*-x64-debian-*.zip
  else
    red "WARNING: could not figure out your system via lsb_release; defaulting to Debian"
    local new_z3_file=fstarlang_binaries/z3-tested/z3-4.8.5*-x64-debian-*.zip
  fi
  local new_z3=4.8.5
  new_z3_file=$(ls $new_z3_file)
  echo "... version of z3 found in z3-tested is: $new_z3_file"

  if [[ $new_z3 != $current_z3 ]]; then
    magenta "Get the freshest z3 from FStarLang/binaries? [Yn]"
    prompt_yes true "exit 1"
    echo "... ls fstarlang_binaries/z3-tested"
    ls -altrh fstarlang_binaries/z3-tested
    echo "... ls $new_z3_file"
    ls -altrh $new_z3_file
    echo "... unzipping $new_z3_file"
    unzip $new_z3_file
    local new_z3_folder=${new_z3_file%%.zip}
    new_z3_folder=${new_z3_folder##fstarlang_binaries/z3-tested/}
    find $new_z3_folder -iname '*.dll' -or -iname '*.exe' | xargs chmod a+x
    magenta "Automatically customize $EVEREST_ENV_DEST_FILE with the z3 path? [Yn]"
    prompt_yes "write_z3_env_dest_file $new_z3_folder" true
    rm -f z3
    ln -sf $new_z3_folder z3
  fi
}

do_check ()
{
  blue "Checking environment"

  # Basic utilities
  success_or "which" "please execute this script in a Unix environment"
  if is_osx; then
    local msg="please run \"brew install gnu-getopt coreutils gnu-sed findutils make\""
    brew --prefix gnu-getopt || echo $msg
    success_or "greadlink" "$msg"
    success_or "gsed" "$msg"
    success_or "gfind" "$msg"
    success_or "gmake" "$msg"
  fi

  # Slightly suboptimal, since we may end up running Cygwin's setup twice.
  if ! command -v git >/dev/null 2>&1; then
    if is_windows; then
      magenta "Git not found. Install Cygwin's git? [Yn]"
      find_cygsetup
      prompt_yes "$cygsetup $cygsetup_args --packages=git"
    else
      red "ERROR: git not found; install it via your favorite package manager"
      exit 1
    fi
  fi

  # Windows pre-requisites
  if is_windows; then
    # A list of known causes for failure
    if where.exe bash.exe | grep -v cygwin >/dev/null 2>&1; then
      red "ERROR: bash.exe has been found in a non-standard location!"
      echo "Please remove Bash for Windows and others (GNU for Windows, MSYS2, etc.)"
      red "Are you sure you want to continue? [Yn]"
      prompt_yes true "exit 1"
    else
      echo "... no suspicious bash"
    fi

    if [[ $(uname -m) != "x86_64" ]]; then
      red "ERROR: not a 64-bit Cygwin"
      echo "We've experienced tons of issues with 32-bit Cygwin. Time to upgrade."
      exit 1
    fi
    echo "... 64-bit cygwin"

    if cygwin_has "ocaml" || cygwin_has "flexdll"; then
      red "ERROR: please remove the cygwin ocaml and/or flexdll packages"
      exit 1
    fi
    echo "... no suspicious cygwin packages"

    if ! (flexlink.exe -help 2>&1 || true) | grep "fdopen" >/dev/null; then
        red "Warning: you have an unknown version of flexlink"
        red "Please use the version from https://fdopen.github.io/opam-repository-mingw/"
    else
        echo "... flexlink is good"
    fi

    # The list of required cygwin packages
    for p in $(cat cygwin-packages); do
      if ! cygwin_has $p; then
        find_cygsetup
        echo "Cygwin package $p is missing"
        if_yes "$cygsetup $cygsetup_args --packages=$(cat cygwin-packages | tr '\n' ,)"
      fi
    done
    echo "... all $(cat cygwin-packages | wc -l) cygwin packages seem to be installed"

    if ! command -v libsqlite3-0.dll >/dev/null 2>&1; then
      red "Warning: x86_64-mingw32 DLLs not in PATH"
      magenta "Automatically customize $EVEREST_ENV_DEST_FILE with the x86_64-mingw32 path + native windows symlinks?"
      prompt_yes write_cygwin_env_dest_file true
    else
      echo "... proper mingw directory seems to be in PATH"
    fi

    if [[ -z "$CXX" ]] ; then
      red "Warning: CXX not defined"
      magenta "Automatically set CXX to x86_64-w64-mingw32-g++.exe?"
      prompt_yes write_cxx_env_dest_file true
    fi
  fi # if is_windows

  # Note: ssh returns the exit code of the remote command (1 in this case),
  # hence the || true -- the success of this step is determined by the presence
  # of "authenticated".
  if ! (ssh -oStrictHostKeyChecking=no git@github.com 2>&1 || true) | grep authenticated >/dev/null; then
    magenta "Warning: git client not configured with the proper ssh credentials"
    echo "Hint: check which git you're running, and make sure you have the same SSH key in ~/.ssh and github.com"
  else
    echo "... github.com access ok"
  fi

  # OCaml detection
  if ! command -v >/dev/null 2>&1 ocaml; then
    # Offer to install and sed-setup a crappy snapshot
    if is_windows; then
      magenta "No OCaml detected!"
      cat <<MSG

Proceed with the download?
MSG
      prompt_yes true "exit 1"
      if [ -e ~/.opam ]; then
        red "Warning: stale ~/.opam; continue? [Yn]"
        prompt_yes true "exit 1"
      fi
      if [ -e /cygdrive/c/ocamlmgw64 ]; then
        red "Warning: stale /cygdrive/c/ocamlmgw64; continue? [Yn]"
        prompt_yes true "exit 1"
      fi
      # Download and Install OPAM
      wget $OPAM_URL
      tar -xf 'opam64.tar.xz'
      rm -f 'opam64.tar.xz'
      bash opam64/install.sh
      echo "Interactive is: $INTERACTIVE ; auto-setup is: $OPAM_AUTO_SETUP ; dot-profile is: $EVEREST_ENV_DEST_FILE ;"
      opam init default "https://github.com/fdopen/opam-repository-mingw.git#opam2" -c "ocaml-variants.$OPAM_VERSION" --disable-sandboxing
      if { ! $INTERACTIVE ; } && ! grep 'opam-init' "$EVEREST_ENV_DEST_FILE"  >/dev/null ; then
        # --auto-setup might not have worked, so manually do it here.
        # Do not expand variables in the textual output.
        echo '. "$HOME/.opam/opam-init/init.sh" > /dev/null 2>/dev/null' >> "$EVEREST_ENV_DEST_FILE"
      fi
      eval $(opam config env)
    else
      red "ERROR: no ocaml found in PATH"
      if is_osx; then
        echo "Hint: brew install ocaml opam"
      else
        echo "Please use your distribution's package management system to install ocaml and opam"
        echo "Note: on older Ubuntus, see https://launchpad.net/~avsm/+archive/ubuntu/ppa"
      fi
      exit 1
    fi

  else
    # OCaml; if this exits, set -e means this is a hard error
    ocaml -noinit -noprompt -stdin <<OCAML
      if Sys.ocaml_version < "$MINIMAL_OCAML_VERSION" then begin
        print_endline "ERROR: Everest needs OCaml >= $MINIMAL_OCAML_VERSION";
        print_endline ("You have OCaml " ^ Sys.ocaml_version);
        exit 1
      end
OCAML
    echo "... ocaml minimum version requirements met"
  fi

  # OCamlfind & extra packages. Required OPAM packages are stored in
  # [opam-packages], where each line is of the form:
  #   <ocamlfind-package-name> <SPACE> <opam-package-name>
  success_or "opam"
  if [ ! -d ~/.opam ]; then
    if is_windows; then
      echo "This is a Windows environment; not running opam init."
      echo "Please follow instructions for the installer you picked."
      echo "Hint: https://github.com/protz/ocaml-installer/wiki or https://fdopen.github.io/opam-repository-mingw/"
    else
      if_yes "opam init"
    fi
    eval $(opam config env)
  fi

  if ! command -v ocamlfind >/dev/null 2>&1; then
    magenta "ocamlfind not found!"
    if_yes "opam install ocamlfind"
  fi

  missing=false
  while read line; do
    ocamlfind_package=$(echo $line | cut -d " " -f 1)
    opam_package=$(echo $line | cut -d " " -f 2)
    if ! ocamlfind query $ocamlfind_package >/dev/null 2>&1; then
      red "ERROR: ocamlfind package $ocamlfind_package is not installed"
      missing=true
      break
    fi
  done < opam-packages
  if $missing; then
    if_yes "install_all_opam_packages"
  fi
  echo "... all $(cat opam-packages | wc -l) ocamlfind packages found"

  # Check for caveats using my OCaml installer
  if ! (cd test && ocamlbuild test.native -use-ocamlfind >compiler_output 2>&1); then
    red "Cannot compile the test OCaml program (see errors in test/compiler_output)"
    red "Maybe you've been using the OCaml installer for windows"
    echo Suggestion: check \
      https://github.com/protz/ocaml-installer/wiki#package-specific-hints and \
      follow instructions for ppx deriving and friends
    exit 1
  fi
  rm -f test/compiler_output
  echo "... sample ocamlbuild project compiles successfully"

  if is_windows && [ -d "/cygdrive/c/OCaml/lib/camlp4" ] && [[ $CAMLP4LIB == "" ]]; then
    red "Warning: seems like you're using the OCaml installer for windows"
    echo There is a bug in the installer -- please see \
      https://github.com/protz/ocaml-installer/wiki#configure-your-initial-opam-setup \
      and add \"export CAMLP4LIB=C:/OCaml/lib/camlp4\" in your "$EVEREST_ENV_DEST_FILE"
  fi

  if is_windows ; then
      # the latest ocaml-stdint segfaults on Windows with
      # 128-bit integers (confirmed on gcc-9 at least)
      # so we need to test whether it works, and if not,
      # then we pull a homemade patch that recompiles it with
      # C compiler optimizations disabled
      if ! [[ -d ocaml-stdint ]] ; then
          echo "... cloning tahina-pro/ocaml-stdint"
          try_git_clone "git@github.com:tahina-pro/ocaml-stdint.git" "https://github.com/tahina-pro/ocaml-stdint.git" ocaml-stdint
      fi
      echo "... building ocaml-stdint test"
      (cd ocaml-stdint && git clean -ffdx)
      ocamlfind ocamlopt -package str,qcheck,stdint ocaml-stdint/tests/stdint_test.ml -linkpkg -o ocaml-stdint/tests/stdint_test.exe
      echo "... running ocaml-stdint test"
      if
          { ocaml-stdint/tests/stdint_test.exe > /dev/null ; } ||
          [[ $? -le 1 ]] # tests fail, but should not segfault
      then
          echo "... ocaml-stdint works well"
      else
          magenta "ERROR: Your ocaml stdint package does not work with your C compiler."
          magenta "Do you want to have it recompiled with -O0 and reinstalled? [Yn]"
          prompt_yes true "exit 1"
          echo "... recompiling and reinstalling ocaml-stdint from tahina-pro/ocaml-stdint"
          (
              cd ocaml-stdint &&
              git clean -ffdx &&
              $MAKE &&
              $MAKE tests/stdint_test &&
              { { tests/stdint_test.exe > /dev/null ; } || [[ $? -le 1 ]] ; } &&
              dune install
          )
      fi
  fi

  # Check for Node.js
  if ! which node >/dev/null 2>&1 ; then
    red "ERROR: Node.js doesn\'t seem to be installed"
    if is_windows ; then
      magenta "Download it from the internet? [Yn]"
      prompt_yes true "exit 1"
      # There is no clean way to determine the latest version of
      # Node.js available. However, the URL below points to a HTML
      # page containing a list of files, and there, there is exactly
      # one link to a .msi file corresponding to 64-bit platforms. So
      # we just need to extract its name from the page.
      NODEJS_MSI=$(wget --output-document=- --no-verbose --quiet https://nodejs.org/dist/latest/ | grep -o '"node-[^-]*-x64\.msi"' | sed 's!"!!g')
      # Check that there are exactly one .msi file there
      test $(echo "$NODEJS_MSI" | grep -o '\.msi' | wc -l) -eq 1
      # Finally, launch Windows installer in unattended mode
      msiexec /i "https://nodejs.org/dist/latest/$NODEJS_MSI" /quiet /passive
      # Test whether Node.js installed properly
      # Impossible: Windows PATH has changed, we cannot refresh it
      # which node > /dev/null 2>&1
      red "CRITICAL: Windows PATH has changed, please restart a new Cygwin window"
    else
      echo "Please install node.js through your package manager"
      exit 1
    fi
  fi
  echo "... Node.js found in PATH"

  # .NET 6.0 (needed to compile F* ulib/fs)
  if dotnet --list-sdks | grep '^6\.0\.' >/dev/null ; then
    echo "... dotnet with .NET SDK 6.0 found"
  else
    red "ERROR: .NET SDK 6.0 not found"
    if is_windows ; then
	magenta "Install it with winget? [Yn]"
	prompt_yes "winget install Microsoft.DotNet.SDK.6"
    else
	echo "Install .NET SDK 6.0 https://docs.microsoft.com/en-us/dotnet/core/install/"
	exit 1
    fi
  fi

  do_update_z3

  if is_windows; then
    if [[ $(echo $FSTAR_HOME | cut -c 1 | tr -d '\r\n' ) == "/" ]]; then
      magenta "You are on windows but your FSTAR_HOME is a Cygwin-style path."
      magenta "Don't do that, follow the suggestion below, and check all your other *_HOME variables."
      unset FSTAR_HOME
    fi
  fi

  echo
  magenta "Remember to run source \"$EVEREST_ENV_DEST_FILE\" if it was modified!"
  local xpwd=""
  if is_windows; then
      xpwd="$(cygpath -m $(pwd))"
  else
      xpwd="$(pwd)"
  fi

  magenta "Note: you *may* want to add ${xpwd}/FStar/bin and ${xpwd}/karamel to your PATH"
  [ -n "${FSTAR_HOME}" ] || \
    magenta "Note: you *may* want to export FSTAR_HOME=${xpwd}/FStar"
  [ -n "${KRML_HOME}" ] || \
    magenta "Note: you *may* want to export KRML_HOME=${xpwd}/karamel"
  [ -n "${PULSE_HOME}" ] || \
    magenta "Note: you *may* want to export PULSE_HOME=${xpwd}/pulse"
  [ -n "${STEEL_HOME}" ] || \
    magenta "Note: you *may* want to export STEEL_HOME=${xpwd}/steel"
  [ -n "${HACL_HOME}" ] || \
    magenta "Note: you *may* want to export HACL_HOME=${xpwd}/hacl-star"
}

get_vale ()
{
  HACL_HOME=$PWD/hacl-star hacl-star/tools/get_vale.sh
}

self_update () {
  check_no_archive
  old_revision=$(git rev-parse HEAD)
  git pull --rebase
  if [[ $(git rev-parse HEAD) != $old_revision ]]; then
    blue "Self-updating to new everest revision $(git rev-parse HEAD | cut -c 1-8)"
    # Now, we transfer execution to the new version of $0
    cd "$initial_pwd"
    exec "${@/pull/}"
  else
    echo "No new everest revision available"
  fi
}

do_pull () {
  source hashes.sh
  source repositories.sh
  echo Reset working copies
  do_reset
}

symlink_clone_warned=false

check_subp_exists () {
  check_no_archive
  local r=$1
  if [ ! -d $r ]; then
    if [ -e $r ]; then
      red "$r exists but is not a directory, aborting"
      exit 1
    fi
    if ! $symlink_clone_warned; then
      echo Note: you\'re welcome to create symbolic links if you already have \
        cloned the repository elsewhere
      symlink_clone_warned=true
    fi
    try_git_clone ${repositories[$r]} ${https[$r]} $r
  fi
}

do_reset ()
{
  for r in $ALL_PROJECTS; do
    echo
    blue "Pulling $r"
    # Some sanity checks, and clone the repositories that aren't there already
    check_subp_exists "$r"

    # Note: the snapshot command guarantees that the commit was pushed to a
    # branch of the form origin/foo. So, we checkout foo, because there's a good
    # chance it tracks origin/foo which contains the commit we want. If it's not
    # the case it's a crazy setup and the user is on their own.
    cd $r
    git fetch
    hash=${hashes[$r]}
    branch=${branches[$r]}
    if [[ $(git symbolic-ref HEAD) != $branch ]]; then
      git checkout -f $branch
    fi
    # Note: this is not super robust in the face of weird cases like someone
    # having a local branch named origin/master, in which case [upstream] will
    # contain "remotes/origin/master"... alternate solution:
    # local found=false
    # for b in $(git branch -r --contains $hash | awk '{ print $0; }'); do
    #   if [[ $upstream == $(git rev-parse --abbrev-ref --symbolic-full-name $b@{u} ]]; then
    #     found=true
    #   fi
    #  done
    # if ! $found; then
    #   etc.
    # fi
    # Note: the --format option of git branch would be better than awk but a lot of
    # people are stuck on git 2.8, including cygwin and Azure VMs.
    upstream=$(git rev-parse --abbrev-ref --symbolic-full-name @{u})
    if ! git branch -r --contains $hash | egrep "^ +$upstream$" >/dev/null 2>&1; then
      red "ERROR: in repository $r, the hash $hash claims to belong to branch \
        $branch, but $branch pulls from $upstream which does not contain $hash"
      exit 1
    fi
    git reset --hard $hash
    git submodule update --init
    cd ..
  done
  get_vale
}

do_advance ()
{
  for r in $ALL_PROJECTS; do
    echo
    blue "Advancing $r"
    check_subp_exists "$r"

    pushd $r
    branch=${branches[$r]}

    if ( ! $ADVANCE_YES ) && ( git status -s -uall | grep -q . ); then
        red "project $r has local changes, aborting advance (pass --yes to ignore)"
        exit 1
    fi

    git checkout -f $branch
    git fetch
    git reset --hard origin/$branch
    git submodule update --init
    popd
  done
}

do_archive ()
{
  TEMPDIR=$(mktemp -d -p .)
  OUTDIR0=${TEMPDIR}/everest/
  OUTDIR=$(realpath ${OUTDIR0})

  # Make sure every subproject is there.
  for r in ${!repositories[@]}; do
    check_subp_exists "$r"
  done

  # Now we're sure hacl-star is there, so we have
  # hacl-star/vale/.vale_version. Fetch that version of vale.
  get_vale

  # Go through each sub-repository (including the openssl submodule for MLCrypto)
  # and put them in the staging directory ${OUTDIR}
  mkdir -p ${OUTDIR}
  for r in ${!repositories[@]} MLCrypto/openssl/; do
    echo
    blue "Archiving $r"

    pushd $r
      if ( git status -s -uall | grep -q . ); then
          red "WARNING: project $r has local changes which will not be reflected in the archive"
      fi
      git archive HEAD --prefix "$r/" | tar -C ${OUTDIR} -x
    popd
  done

  # Copy vale
  if $VALE_ARCHIVE; then
    cp -r vale/ ${OUTDIR}/vale
    rm ${OUTDIR}/vale/vale-release.zip # Not needed, save some space
  fi

  # Remove unneded (and large) files from the staging directory.
  rm ${OUTDIR}/FStar/src/VS/.nuget/NuGet.exe
  rm -r ${OUTDIR}/MLCrypto/openssl/fuzz/corpora/
  rm -r ${OUTDIR}/mitls-fstar/tests/

  cp everest \
     opam-packages \
     hashes.sh \
     repositories.sh \
     lib.sh \
     LICENSE \
     README.md \
       ${OUTDIR}

  $SED -i 's/^IS_ARCHIVE=.*/IS_ARCHIVE=true/' ${OUTDIR}/everest

  rm -f everest_archive.tar{,.xz} # Clean old files if any
  tar -C ${TEMPDIR} -c -f everest_archive.tar everest/
  rm -r ${TEMPDIR}
  blue "Compressing archive..."
  xz --extreme -9 everest_archive.tar
}

do_merge ()
{
  self_update
  blue "Merging working copies"
  for r in $ALL_PROJECTS; do
    echo
    blue "Pulling and rebasing $r"
    cd $r
    git pull --rebase
    cd ..
  done
}

do_forall ()
{
  #blue "Executing on toplevel"
  #"$@"
  for r in ${!repositories[@]}; do
    echo
    blue "Executing in $r"
    (cd $r && "$@" || red "return code was $?, carrying on anyway")
  done
}

clean_hacl () {
  for f in \
    hacl-star/ \
  ; do
    if test -d "$f" ; then
      $MAKE -C "$f" clean
    fi
  done
}

setup_env () {
  if is_windows; then
    export FSTAR_HOME=$(cygpath -m $(pwd)/FStar)
    export VALE_HOME=$(cygpath -m $(pwd)/vale)
    export KRML_HOME=$(cygpath -m $(pwd)/karamel)
    export PULSE_HOME=$(cygpath -m $(pwd)/pulse)
    export STEEL_HOME=$(cygpath -m $(pwd)/steel)
    export HACL_HOME=$(cygpath -m $(pwd)/hacl-star)
    export MLCRYPTO_HOME=$(cygpath -m $(pwd)/MLCrypto)
    export EVERPARSE_HOME=$(cygpath -m $(pwd)/everparse)
    export MITLS_HOME=$(cygpath -m $(pwd)/mitls-fstar)
  else
    export FSTAR_HOME=$(pwd)/FStar
    export VALE_HOME=$(pwd)/vale
    export KRML_HOME=$(pwd)/karamel
    export PULSE_HOME=$(pwd)/pulse
    export STEEL_HOME=$(pwd)/steel
    export HACL_HOME=$(pwd)/hacl-star
    export MLCRYPTO_HOME=$(pwd)/MLCrypto
    export EVERPARSE_HOME=$(pwd)/everparse
    export MITLS_HOME=$(pwd)/mitls-fstar
  fi
  export OPENSSL_HOME=$MLCRYPTO_HOME/openssl
  magenta "exported FSTAR_HOME=$FSTAR_HOME"
  magenta "exported OPENSSL_HOME=$OPENSSL_HOME"
  magenta "exported KRML_HOME=$KRML_HOME"
  magenta "exported PULSE_HOME=$PULSE_HOME"
  magenta "exported STEEL_HOME=$STEEL_HOME"
  magenta "exported VALE_HOME=$VALE_HOME"
  magenta "exported HACL_HOME=$HACL_HOME"
  magenta "exported MLCRYPTO_HOME=$MLCRYPTO_HOME"
  export PATH=$(pwd)/FStar/bin:$(pwd)/karamel:$PATH

  if is_windows; then
    export PATH=$(cygpath -u $OPENSSL_HOME):$PATH
  elif [[ $(uname) == "Darwin" ]]; then
    export DYLD_LIBRARY_PATH=$OPENSSL_HOME:$DYLD_LIBRARY_PATH
    magenta "exported DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH"
  else
    export LD_LIBRARY_PATH=$OPENSSL_HOME:$LD_LIBRARY_PATH
    magenta "exported LD_LIBRARY_PATH=$LD_LIBRARY_PATH"
  fi
  magenta "exported PATH=$PATH"
}

separator () {
  echo "================================================================================"
}

set_windows () {
  export EVEREST_WINDOWS=1
}

set_opt () {
  # Picked up by pretty much all the Makefiles
  export CFLAGS="-funroll-loops -fomit-frame-pointer -O3"
}

set_openssl () {
  # Picked up by mitls-fstar/src/tls/Makefile.Karamel
  export MITLS_USE_OPENSSL=1
}

build_fstar () {
  $MAKE -C FStar $make_opts
}

build_karamel () {
  # TODO: run the karamel testsuite too
  $MAKE -C karamel $make_opts &&
  $MAKE -C karamel/krmllib $make_opts
}

build_hacl () {
  # Force regeneration of each target as part of Everest build, for maximum
  # testing. This is not necessarily the optimal scenario for someone who just
  # wants to build HACL*. Note: based on version control mtimes, if we weren't
  # deleting these, make would think that Makefile.basic is more recent than the
  # source files.
  rm -rf hacl-star/dist/*/{Makefile.basic,package.json}
  $MAKE -C hacl-star $make_opts
}

build_mitls () {
  CFLAGS="$MITLS_CFLAGS" \
  $MAKE -C mitls-fstar/src/tls $make_opts && \
  true
  # $MAKE -C mitls-fstar/apps/quicMinusNet $make_opts
  # $MAKE -C mitls-fstar/apps/cmitls $make_opts && \
  # $MAKE -C mitls-fstar/libs/ffi $make_opts && \
  # $MAKE -C mitls-fstar/src/pki $make_opts && \
}

do_make ()
{
  setup_env
  failed=""
  mkdir -p log

  declare -A build_commands
  build_commands[FStar]="build_fstar"
  build_commands[karamel]="build_karamel"
  build_commands[pulse]="$MAKE -C pulse $make_opts"
  build_commands[steel]="$MAKE -C steel $make_opts"
  build_commands[MLCrypto]="$MAKE -C MLCrypto $make_opts"
  build_commands[hacl-star]="build_hacl"
  build_commands[mitls-fstar]="build_mitls"
  build_commands[everparse]="$MAKE -C everparse $make_opts"
  build_commands[everquic-crypto]="make -C everquic-crypto dist/libeverquic.a $make_opts"
  build_commands[merkle-tree]="make -C merkle-tree dist/libmerkletree.a $make_opts"

  # Order matters.
  for p in FStar karamel pulse steel MLCrypto hacl-star merkle-tree everparse everquic-crypto mitls-fstar; do
    # For individual components, we set ALL_PROJECTS=foo
    if [[ ${ALL_PROJECTS/$p/} == $ALL_PROJECTS ]]; then
      continue
    fi
    separator
    blue "Rebuilding $p"
    blue "Running: ${build_commands[$p]}"
    if ! ${build_commands[$p]} ; then
      separator
      red "FAILURE: build failed for $p"
      return 2
    fi
    separator
    echo -e "\n\n"
  done

  green "SUCCESS"
}

do_test () {
  check_no_archive
  setup_env

  separator
  blue "Running tests (commands shown below)"
  set -x
  # pulse
  $MAKE -C pulse test $make_opts
  # steel
  $MAKE -C steel test $make_opts
  # karamel
  LD_LIBRARY_PATH= $MAKE -C karamel/test $make_opts everything
  # evercrypt
  # LD_LIBRARY_PATH is already taken care of by the HACL* Makefile
  LD_LIBRARY_PATH= $MAKE -C hacl-star test $make_opts
  # everquic-crypto
  make -C merkle-tree $make_opts test
  # everparse
  $MAKE -C everparse $make_opts test
  # everquic-crypto
  make -C everquic-crypto $make_opts test
  # mitls; note: these tests make assumption on their current working directory
  (cd mitls-fstar/src/tls && $MAKE $make_opts test)
  # (cd mitls-fstar/apps/cmitls && $MAKE $keep_going_opt test)
  # (cd mitls-fstar/apps/quicMinusNet && $MAKE $keep_going_opt test)
  set +x
  separator
}

do_verify () {
  setup_env

  declare -A verify_commands
  verify_commands[FStar]="$MAKE -C FStar/src ulong $make_opts"
  verify_commands[karamel]="echo nothing to verify for karamel"
  verify_commands[pulse]="echo nothing to verify for pulse"
  verify_commands[steel]="echo nothing to verify for steel"
  verify_commands[hacl-star]="$MAKE -C hacl-star $parallel_opt -k verify"
  verify_commands[mitls-fstar]="$MAKE -C mitls-fstar/src/tls verify $parallel_opt -k"
  verify_commands[MLCrypto]="echo nothing to verify for MLCrypto"
  verify_commands[everparse]="echo nothing to verify for everparse"
  verify_commands[everquic-crypto]="echo nothing to verify for everquic-crypto"
  verify_commands[merkle-tree]="echo nothing to verify for merkle-tree"

  for p in $ALL_PROJECTS; do
    separator
    blue "Running verification for: $p"
    ${verify_commands[$p]}
    separator
  done
}

do_clean_c ()
{
  setup_env
  for d in karamel/krmllib hacl-star/ \
    mitls-fstar/src/tls
  do
    if test -d "$d" ; then
      $MAKE -C "$d" clean-c
    fi
  done
}

do_clean ()
{
  setup_env
  for d in FStar/ulib/ml FStar/src{,/ocaml-output} \
    MLCrypto/{,openssl} \
    everparse \
    everquic-crypto \
    merkle-tree \
    mitls-fstar/src/tls \
    pulse \
    steel \
    karamel \
    ; do
    if test -d "$d" ; then
      $MAKE -C "$d" clean
    fi
  done
  clean_hacl
}

do_snapshot ()
{
  blue "Recording a new snapshot"
  echo "declare -A hashes" > new-hashes.sh
  echo "declare -A branches" >> new-hashes.sh
  for r in $(echo ${!repositories[@]} | tr ' ' '\n' | sort -f) ; do
    cd $r
    head=$(git rev-parse HEAD)
    branch=$(git symbolic-ref HEAD)
    branch=${branch##refs/heads/}
    upstream=$(git rev-parse --abbrev-ref --symbolic-full-name @{u})
    if [[ $upstream != "origin/$branch" ]]; then
      red "ERROR: in repository $r, HEAD ($head) is on $branch which pushes to \
        $upstream, not origin/$branch!"
    fi
    if ! git branch -r --contains $head | egrep "origin/$branch$" >/dev/null 2>&1; then
      red "ERROR: in repository $r, HEAD ($head) is on $branch which has not
        been pushed to $upstream"
    fi
    cd ..
    echo "recording $r at revision $(echo $head | cut -c 1-8) ($branch)"
    echo "hashes[$r]=$head" >> new-hashes.sh
    echo "branches[$r]=$branch" >> new-hashes.sh
  done
  mv new-hashes.sh hashes.sh
  cat <<MSG

New hashes have been recorded in hashes.sh. You can see the changes with git
diff.

If you intend to make this set of working revisions widely available, then you
must run commit and push.
MSG
}

do_drop ()
{
  check_no_archive
  setup_env

  blue "Dropping sources for Windows libraries"
  ./make-source-drop mitls-fstar/src/windows
}

do_qbuild ()
{
  check_no_archive
  setup_env

  # Windows only: Visual Studio's command line to set up environment (VS_ENV_CMD)
  blue "Checking for Visual Studio"
  # Starting from Visual Studio 2017, version 15.2 or later,
  # we can determine the location of a VS install
  # using vswhere.exe, see:
  # https://docs.microsoft.com/en-us/visualstudio/extensibility/locating-visual-studio
  if
    VSWHERE_WINDOWS="$(cmd.exe /C 'echo %ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe' | sed 's!\r!!g')" &&
    VSWHERE=$(cygpath -u "$VSWHERE_WINDOWS") &&
    VS_HOME=$("$VSWHERE" -requires Microsoft.VisualStudio.Component.FSharp -format value -property InstallationPath | head -1 | sed 's!\r!!g') &&
    [[ -n "$VS_HOME" ]]
  then
    echo ... found Visual Studio 2017 or later at $VS_HOME
    # Visual Studio 2017 (15.2) or later
    # vcvarsall.bat has been superseded by vsdevcmd.bat, see:
    # https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/compiler-options/how-to-set-environment-variables-for-the-visual-studio-command-line
    VSDEVCMD_PATH=$(cygpath -u "$VS_HOME")/Common7/Tools
    VSDEVCMD=$(cygpath -w "$VSDEVCMD_PATH/VsDevCmd.bat")
    # Here we assume that BOTH the target platform
    # and the host platform are amd64.
    VS_ENV_CMD='"'"$VSDEVCMD"'" -arch=amd64 -host_arch=amd64'
  else
    # Older versions are based on vcvarsall.bat
    if [[ -v VS140COMNTOOLS ]]; then
      # Visual Studio 2015 (14.x)
      VS_TOOLS_PATH="$VS140COMNTOOLS"
    elif [[ -v VS120COMNTOOLS ]]; then
      # Visual Studio 2012 (12.x)
      VS_TOOLS_PATH="$VS120COMNTOOLS"
    elif [[ -v VS110COMNTOOLS ]]; then
      # Visual Studio 2010 (10.x)
      VS_TOOLS_PATH="$VS110COMNTOOLS"
    else
      # Not found
      echo Could not find Visual Studio
      exit 1
    fi
    VCVARSALL_PATH="$VS_TOOLS_PATH"/../../VC
    VCVARSALL=$(cygpath -d "$VCVARSALL_PATH/vcvarsall.bat")
    # Here we assume that BOTH the target platform
    # and the host platform are amd64.
    VS_ENV_CMD="$VCVARSALL amd64"
  fi

  blue "Building Windows libraries"
  # Instead of invoking cmd.exe /c, which would force us to
  # rely on its flaky semantics for double quotes,
  # we go through a batch file.
  THIS_PID=$$
  # Find an unambiguous file name for our .bat file
  NMAKE_EXECS=0
  while
    NMAKE_INVOKE_FILE="everest$THIS_PID""nmake$NMAKE_EXECS"".bat" &&
    [[ -e "$NMAKE_INVOKE_FILE" ]]
  do
    NMAKE_EXECS=$(($NMAKE_EXECS + 1))
  done
  # Then create, run and remove the .bat file
  DIR=$(cygpath -w "$(pwd)/mitls-fstar/src/windows")
  cat > "$NMAKE_INVOKE_FILE" <<EOF
call $VS_ENV_CMD
set MAKEFLAGS=
set KRML_HOME=..\..\..\karamel
cd "$DIR\krmllib" &&^
call nmake -f makefile.vs &&^
cd "$DIR\evercrypt" &&^
call nmake -f makefile.vs &&^
cd "$DIR\quiccrypto" &&^
call nmake -f makefile.vs &&^
cd "$DIR\mitls" &&^
call nmake -f makefile.vs
EOF
  chmod +x "$NMAKE_INVOKE_FILE"
  "./$NMAKE_INVOKE_FILE"
  NMAKE_RETCODE=$?
  rm -f "$NMAKE_INVOKE_FILE"
  return $NMAKE_RETCODE
}

# Non-Dockerized continuous integration (CI with persistent state)

do_ci () {
    mkdir -p ocaml-packages
    if is_windows ; then
        export OCAMLFIND_DESTDIR=$(cygpath -m $PWD/ocaml-packages)
        export OCAMLPATH="$OCAMLFIND_DESTDIR;$OCAMLPATH"
    else
        export OCAMLFIND_DESTDIR=$PWD/ocaml-packages
        export OCAMLPATH=$OCAMLFIND_DESTDIR:$OCAMLPATH
    fi
    do_reset
    do_make
    do_test
}

do_shell() {
  setup_env
  echo -n "# Switching back to "
  cd -
  exec "${@:-$SHELL}"
}

# ------------------------------------------------------------------------------
# Usage and parsing arguments
# ------------------------------------------------------------------------------

print_usage ()
{
  cat <<HELP
OVERVIEW: $0, a high-level management script for Project Everest

USAGE: $0 [OPTIONS] [PROJECTS] COMMANDS

OPTION:
  --yes     Non-interactive mode (answer y to all questions, verbose)

  --admit   Admit F* SMT queries (warning: unsafe!)

  -j n      Set max number of parallel jobs to n (default 1)

  -windows  Build for Windows (Tune for MSVC compiler: optimize tail recursion, etc.)

  -k        Pass the -k (--keep-going) option to "make"

  -opt      Enable classic optimization flags and disable debugging. Note: this
            does not invalidate previous object files (e.g. in HACL*); consider
            cleaning.

  -openssl  Use OpenSSL for AEAD in miTLS

PROJECT:
  The commands
    pull reset advance merge make
  can be restricted to operate on one or many of the following:
    FStar karamel mitls-fstar hacl-star merkle-tree MLCrypto everparse everquic-crypto
  to restrict the projects to a subset, pass them in separate arguments
  before any command, e.g.:
    ./everest FStar karamel everparse make -k -j16

COMMAND:
  check     ensure that all the required programs are found in path, install
            them if needed; offer to customize ~/.bash_profile with proper env
            variables
            (destination file ~/.bash_profile can be overridden with the
            EVEREST_ENV_DEST_FILE environment variable)

  opam      install the needed OPAM packages (implied by check)

  z3        install the right version of z3 (implied by check)

  pull      self-update the everest repository (i.e. the script and
            hashes.sh) then run reset

  advance   advance every project by pulling from their tracked branches

  get_vale  install the right version of vale binary (implied by pull)

  merge     pull all projects, merging and rebasing local changes; does NOT
            reset to known to be good version, but preserves your changes

  forall    execute command in all git repository directories

  reset     pull all projects and move them to the revisions specified by
            hashes.sh

  snapshot  make the current state a new known set of working revisions; this
            writes into hashes.sh

  make      rebuild and verify all projects

  test      launch the test artifacts

  drop      drop extraced C and assembly files from miTLS and Hacl*

  qbuild    build Windows libraries using Visual Studio

  archive   create an xzipped tarball with all the Everest sources; the
            archive can be built without an internet connection and is
            meant to be small in size (so it does not include Git history);
            you can use the --no-vale-archive to exclude vale binaries and
            obtain a smaller archive

  clean-c   only clean generated C files, useful when switching to -windows

  clean     clean all projects

  shell     run a shell with the correct FSTAR_HOME/... environment variables

  help      print the current message
HELP
}

OPTIONS=j:k
LONGOPTS=yes,windows,openssl,opt,admit,no-vale-archive

# Temporarily stores output to check for errors
# --alternative allows long options to start with a single '-'
! PARSED=$($GETOPT --alternative --options=$OPTIONS --longoptions=$LONGOPTS --name "$0" -- "$@")
if [[ ${PIPESTATUS[0]} -ne 0 ]]; then
    exit 2
fi

eval set -- "$PARSED"

# Read options until --
while true; do
    case "$1" in
        -j)
            parallel_opt="-j $2"
            set_make_opts
            shift 2
            ;;

        -k)
            keep_going_opt="-k"
            set_make_opts
            shift
            ;;

        -yes|--yes)
            make_non_interactive
            shift
            ;;

        -windows|--windows)
            set_windows
            shift
            ;;

        -openssl|--openssl)
            set_openssl
            shift
            ;;

        -opt|--opt)
            set_opt
            shift
            ;;

        -admit|--admit)
            export OTHERFLAGS="$OTHERFLAGS --admit_smt_queries true"
            shift
            ;;

        -no-vale-archive|--no-vale-archive)
            VALE_ARCHIVE=false
            shift
            ;;

        --)
            shift
            break
            ;;
        *)
            echo "Unexpected error parsing options"
            exit 3
            ;;
    esac
done

# Handle commands
if [[ $# -eq 0 ]]; then
    print_usage
    exit 0
fi

while true; do
  if [[ $# -eq 0 ]]; then
    exit 0
  fi
  case "$1" in
    ci)
      do_ci
      ;;

    check)
      do_check
      ;;

    pull)
      self_update
      do_pull
      ;;

    pull_projects)
      do_pull
      ;;

    advance)
      do_advance
      ;;

    pull_vale)
      get_vale
      ;;

    merge)
      do_merge
      ;;

    forall)
      shift
      do_forall "$@"
      break
      ;;

    FStar|mitls-fstar|karamel|hacl-star|MLCrypto|everparse|merkle-tree|everquic-crypto|pulse|steel)
      if $SELECTIVE; then
        ALL_PROJECTS="$ALL_PROJECTS,$1"
      else
        ALL_PROJECTS="$1"
        SELECTIVE=true
      fi
      ;;

    reset)
      do_reset
      ;;

    make)
      do_make
      ;;

    opam)
      install_all_opam_packages
      ;;

    z3)
      do_update_z3
      ;;

    get_vale)
      get_vale
      ;;

    clean)
      do_clean
      ;;

    clean-c)
      do_clean_c
      ;;

    verify)
      #do_verify
      red "The 'verify' command is obsoleted by 'make'. Just run './everest make' instead."
      ;;

    test)
      do_test
      ;;

    snapshot)
      do_snapshot
      ;;

    drop)
      do_drop
      ;;

    qbuild)
      do_qbuild
      ;;

    archive)
      do_archive
      ;;

    shell)
      shift
      do_shell "$@"
      # do_shell does not return
      ;;

    *)
      print_usage
      exit 1
      ;;
  esac
  shift
done
